# Google dorking notes

* Robots.txt is the first file the crawlers index.
* ```User-agent: <user-agent/*>``` Specify the type of crawlers.
  * Googlebot, msnbot.
* ```Allow: <path>``` Specify the directories the crawler can index.
* ```Disallow: <path>``` Specify the directories the crawler can not index.
* ```Sitemap: https://url/sitemap.xml``` Specify the url of sitemap.

## In google searches

* "searchTerm" searches for only the specified searchterm.
* ```site: site.com searchTerm``` will rank the results from the specified site.
* ```filetype: ext``` will find filetypes with specified extension
* ```cache: url.dom``` will show the cached version of the website.
* ```intitle: phrase``` the specified phrase must appear in the title of the page.
* 

